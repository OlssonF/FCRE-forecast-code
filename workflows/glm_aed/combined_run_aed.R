library(tidyverse)
library(lubridate)
set.seed(100)

options(future.globals.maxSize= 891289600)

Sys.setenv("AWS_DEFAULT_REGION" = "s3",
           "AWS_S3_ENDPOINT" = "flare-forecast.org")

lake_directory <- here::here()

files.sources <- list.files(file.path(lake_directory, "R"), full.names = TRUE)
purrr::walk(files.sources, source)

config_set_name <- "glm_aed"
configure_run_file <- "configure_run.yml"

config <- FLAREr::set_configuration(configure_run_file,lake_directory, config_set_name = config_set_name)
config <- FLAREr::get_restart_file(config, lake_directory)

#message(paste0("     Running forecast that starts on: ", config$run_config$start_datetime))

#Need to remove the 00 ensemble member because it only goes 16-days in the future

#pars_config <- NULL #readr::read_csv(file.path(config$file_path$configuration_directory, "FLAREr", config$model_settings$par_config_file), col_types = readr::cols())
pars_config <- NULL #readr::read_csv(file.path(config$file_path$configuration_directory, config$model_settings$par_config_file), col_types = readr::cols())
obs_config <- readr::read_csv(file.path(config$file_path$configuration_directory, config$model_settings$obs_config_file), col_types = readr::cols())
states_config <- readr::read_csv(file.path(config$file_path$configuration_directory, config$model_settings$states_config_file), col_types = readr::cols())


met_start_datetime <- lubridate::as_datetime(config$run_config$start_datetime)
met_forecast_start_datetime <- lubridate::as_datetime(config$run_config$forecast_start_datetime)

if(config$run_config$forecast_horizon > 16 & config$met$use_forecasted_met & !config$met$use_openmeteo){
  met_forecast_start_datetime <- met_forecast_start_datetime - lubridate::days(1)
  if(met_forecast_start_datetime < met_start_datetime){
    met_start_datetime <- met_forecast_start_datetime
    message("horizon is > 16 days so adjusting forecast_start_datetime in the met file generation to use yesterdays forecast. But adjusted forecast_start_datetime < start_datetime")
  }
}




met_out <- FLAREr::generate_met_files_arrow(out_dir = config$file_path$execute_directory,
                                      start_datetime = met_start_datetime,
                                      end_datetime = config$run_config$end_datetime,
                                      forecast_start_datetime = met_forecast_start_datetime,
                                      forecast_horizon =  config$run_config$forecast_horizon,
                                      site_id = config$location$site_id,
                                      use_s3 = TRUE,
                                      bucket = config$s3$drivers$bucket,
                                      endpoint = config$s3$drivers$endpoint,
                                      use_siteid_s3 = TRUE)

# met_out <- FLAREr::generate_met_files_openmet(out_dir = config$file_path$execute_directory,
#                                               start_datetime = lubridate::as_datetime(config$run_config$start_datetime),
#                                               end_datetime = config$run_config$end_datetime,
#                                               forecast_start_datetime = lubridate::as_datetime(config$run_config$forecast_start_datetime),
#                                               forecast_horizon =  config$run_config$forecast_horizon,
#                                               latitude = config$location$latitude,
#                                               longitude = config$location$longitude,
#                                               site_id = config$location$site_id,
#                                               openmeteo_api = config$met$openmeteo_api,
#                                               model = config$met$openmeteo_model,
#                                               use_archive = config$met$use_openmeteo_archive,
#                                               bucket = config$s3$drivers$bucket,
#                                               endpoint = config$s3$drivers$endpoint)

variables <- c("datetime", "FLOW", "TEMP", "SALT",
               'OXY_oxy',
               'CAR_dic',
               'CAR_ch4',
               'SIL_rsi',
               'NIT_amm',
               'NIT_nit',
               'PHS_frp',
               'OGM_doc',
               'OGM_docr',
               'OGM_poc',
               'OGM_don',
               'OGM_donr',
               'OGM_pon',
               'OGM_dop',
               'OGM_dopr',
               'OGM_pop',
               'PHY_cyano',
               'PHY_green',
               'PHY_diatom')


targets_vera <- readr::read_csv("https://renc.osn.xsede.org/bio230121-bucket01/vera4cast/targets/project_id=vera4cast/duration=P1D/daily-inflow-targets.csv.gz",
                                show_col_types = FALSE)

inflow_hist_dates <- tibble(datetime = seq(min(targets_vera$datetime), max(targets_vera$datetime), by = "1 day"))

targets_vera |>
  filter(!variable %in% c("DN_mgL_sample", "DC_mgL_sample")) |>
  select(datetime, variable, observation) |>
  pivot_wider(names_from = variable, values_from = observation) |>
  right_join(inflow_hist_dates, by = "datetime") |>
  mutate(across(Flow_cms_mean:DIC_mgL_sample, imputeTS::na_interpolation)) |>
  tidyr::fill(Flow_cms_mean:DIC_mgL_sample, .direction = "up") |>
  tidyr::fill(Flow_cms_mean:DIC_mgL_sample, .direction = "down") |>
  dplyr::rename(TEMP = Temp_C_mean,
                FLOW = Flow_cms_mean) |>
  dplyr::mutate(NIT_amm = NH4_ugL_sample*1000*0.001*(1/18.04),
                NIT_nit = NO3NO2_ugL_sample*1000*0.001*(1/62.00), #as all NO2 is converted to NO3
                PHS_frp = SRP_ugL_sample*1000*0.001*(1/94.9714),
                OGM_doc = DOC_mgL_sample*1000*(1/12.01)* 0.10,  #assuming 10% of total DOC is in labile DOC pool (Wetzel page 753)
                OGM_docr = 1.5*DOC_mgL_sample*1000*(1/12.01)* 0.90, #assuming 90% of total DOC is in recalcitrant DOC pool
                TN_ugL = TN_ugL_sample*1000*0.001*(1/14),
                TP_ugL = TP_ugL_sample*1000*0.001*(1/30.97),
                OGM_poc = 0.1*(OGM_doc+OGM_docr), #assuming that 10% of DOC is POC (Wetzel page 755
                OGM_don = (5/6)*(TN_ugL_sample-(NIT_amm+NIT_nit))*0.10, #DON is ~5x greater than PON (Wetzel page 220)
                OGM_donr = (5/6)*(TN_ugL_sample-(NIT_amm+NIT_nit))*0.90, #to keep mass balance with DOC, DONr is 90% of total DON
                OGM_pon = (1/6)*(TN_ugL_sample-(NIT_amm+NIT_nit)), #detemined by subtraction
                OGM_dop = 0.3*(TP_ugL_sample-PHS_frp)*0.10, #Wetzel page 241, 70% of total organic P = particulate organic; 30% = dissolved organic P
                OGM_dopr = 0.3*(TP_ugL_sample-PHS_frp)*0.90,#to keep mass balance with DOC & DON, DOPr is 90% of total DOP
                OGM_pop = TP_ugL_sample-(OGM_dop+OGM_dopr+PHS_frp), # #In lieu of having the adsorbed P pool activated in the model, need to have higher complexed P
                CAR_dic = DIC_mgL_sample*1000*(1/52.515),
                OXY_oxy = rMR::Eq.Ox.conc(TEMP, elevation.m = 506, #creating OXY_oxy column using RMR package, assuming that oxygen is at 100% saturation in this very well-mixed stream
                                          bar.press = NULL, bar.units = NULL,
                                          out.DO.meas = "mg/L",
                                          salinity = 0, salinity.units = "pp.thou"),
                OXY_oxy = OXY_oxy *1000*(1/32),
                CAR_ch4 = CH4_umolL_sample,
                PHY_cyano = 0,
                PHY_green = 0,
                PHY_diatom = 0,
                SIL_rsi = DRSI_mgL_sample*1000*(1/60.08),
                SALT = 0) |>
  dplyr::mutate_if(is.numeric, round, 4) |>
  dplyr::select(dplyr::any_of(variables)) |>
  tidyr::pivot_longer(-c("datetime"), names_to = "variable", values_to = "observation") |>
  dplyr::select(datetime, variable, observation) |>
  readr::write_csv(file.path(config$file_path$qaqc_data_directory, paste0(config$location$site_id, "-targets-inflow.csv")))

inflow_forecast_dir <- "inflow"
convert_vera4cast_inflow(reference_date = lubridate::as_date(config$run_config$forecast_start_datetime),
                           model_id = "inflow_gefsClimAED",
                           save_path = file.path(lake_directory, "drivers", inflow_forecast_dir))


inflow_outflow_files <- FLAREr::create_inflow_outflow_files_arrow(inflow_forecast_dir = inflow_forecast_dir,
                                                          inflow_obs = file.path(config$file_path$qaqc_data_directory, paste0(config$location$site_id, "-targets-inflow.csv")),
                                                          variables = variables,
                                                          out_dir = config$file_path$execute_directory,
                                                          start_datetime = config$run_config$start_datetime,
                                                          end_datetime = config$run_config$end_datetime,
                                                          forecast_start_datetime = config$run_config$forecast_start_datetime,
                                                          forecast_horizon =  config$run_config$forecast_horizon,
                                                          site_id = config$location$site_id,
                                                          use_s3 = FALSE,
                                                          bucket = config$s3$inflow_drivers$bucket,
                                                          endpoint = config$s3$inflow_drivers$endpoint,
                                                          local_directory = file.path(lake_directory, "drivers", inflow_forecast_dir),
                                                          use_forecast = TRUE,
                                                          use_ler_vars = FALSE)

inflow_outflow_files$inflow_file_names <- inflow_outflow_files$inflow_file_names[which(stringr::str_detect(inflow_outflow_files$inflow_file_names, "ens32", negate = TRUE))]
inflow_outflow_files$outflow_file_names <- inflow_outflow_files$outflow_file_names[which(stringr::str_detect(inflow_outflow_files$outflow_file_names, "ens32", negate = TRUE))]


readr::read_csv("https://renc.osn.xsede.org/bio230121-bucket01/vera4cast/targets/project_id=vera4cast/duration=P1D/daily-insitu-targets.csv.gz", show_col_types = FALSE) |>
  dplyr::mutate(observation = ifelse(variable == "DO_mgL_mean", observation*1000*(1/32), observation),
                observation = ifelse(variable == "fDOM_QSU_mean", -151.3407 + observation*29.62654, observation),
                depth_m = ifelse(depth_m == 0.1, 0.0, depth_m)) |>
  dplyr::rename(depth = depth_m) |>
  dplyr::filter(site_id == "fcre",
                datetime >= as_datetime(config$run_config$start_datetime)) |>
  readr::write_csv(file.path(config$file_path$qaqc_data_directory,paste0(config$location$site_id, "-targets-insitu.csv")))


#Create observation matrix
obs <- FLAREr::create_obs_matrix(cleaned_observations_file_long = file.path(config$file_path$qaqc_data_directory,paste0(config$location$site_id, "-targets-insitu.csv")),
                                 obs_config = obs_config,
                                 config)

obs_secchi_depth <- get_obs_secchi_depth(obs_file = file.path(config$file_path$qaqc_data_directory,paste0(config$location$site_id, "-targets-insitu.csv")),
                                         start_datetime = config$run_config$start_datetime,
                                         end_datetime = config$run_config$end_datetime,
                                         forecast_start_datetime = config$run_config$forecast_start_datetime,
                                         forecast_horizon =  config$run_config$forecast_horizon,
                                         secchi_sd = 0.1)

#obs_secchi_depth <- NULL
#obs[ ,2:dim(obs)[2], ] <- NA

states_config <- FLAREr::generate_states_to_obs_mapping(states_config, obs_config)

model_sd <- FLAREr::initiate_model_error(config, states_config)

init <- FLAREr::generate_initial_conditions(states_config,
                                            obs_config,
                                            pars_config,
                                            obs,
                                            config,
                                            historical_met_error = met_out$historical_met_error)
#Run EnKF
da_forecast_output <- FLAREr::run_da_forecast(states_init = init$states,
                                              pars_init = init$pars,
                                              aux_states_init = init$aux_states_init,
                                              obs = obs,
                                              obs_sd = obs_config$obs_sd,
                                              model_sd = model_sd,
                                              working_directory = config$file_path$execute_directory,
                                              met_file_names = met_out$filenames,
                                              inflow_file_names = inflow_outflow_files$inflow_file_name,
                                              outflow_file_names = inflow_outflow_files$outflow_file_name,
                                              config = config,
                                              pars_config = pars_config,
                                              states_config = states_config,
                                              obs_config = obs_config,
                                              management = NULL,
                                              da_method = config$da_setup$da_method,
                                              par_fit_method = config$da_setup$par_fit_method,
                                              obs_secchi = obs_secchi_depth$obs_secchi,
                                              obs_depth = obs_secchi_depth$obs_depth)

# Save forecast

saved_file <- FLAREr::write_forecast_netcdf(da_forecast_output = da_forecast_output,
                                            forecast_output_directory = config$file_path$forecast_output_directory,
                                            use_short_filename = TRUE)

forecast_df <- FLAREr::write_forecast_arrow(da_forecast_output = da_forecast_output,
                                            use_s3 = config$run_config$use_s3,
                                            bucket = config$s3$forecasts_parquet$bucket,
                                            endpoint = config$s3$forecasts_parquet$endpoint,
                                            local_directory = file.path(lake_directory, "forecasts/parquet"))

vera_variables <- c("Temp_C_mean","Chla_ugL_mean", "DO_mgL_mean", "fDOM_QSU_mean", "NH4_ugL_sample",
                    "NO3NO2_ugL_sample", "SRP_ugL_sample", "DIC_mgL_sample","Secchi_m_sample",
                    "Bloom_binary_mean","CH4_umolL_sample","IceCover_binary_max")

# Calculate probablity of bloom
bloom_binary <- forecast_df |>
  dplyr::filter(depth == 1.6 & variable == "Chla_ugL_mean") |>
  dplyr::mutate(over = ifelse(prediction > 20, 1, 0)) |>
  dplyr::summarize(prediction = sum(over) / n(), .by = c(datetime, reference_datetime, pubDate, model_id, site_id, depth, variable)) |>
  dplyr::mutate(family = "bernoulli",
                parameter = "prob",
                variable = "Bloom_binary_mean") |>
  dplyr::rename(depth_m = depth) |>
  dplyr::select(reference_datetime, datetime, model_id, site_id, depth_m, family, parameter, variable, prediction)

# Calculate probablity of having ice
ice_binary <- forecast_df |>
  dplyr::filter(variable == "ice_thickness") |>
  dplyr::mutate(over = ifelse(prediction > 0, 1, 0)) |>
  dplyr::summarize(prediction = sum(over) / n(), .by = c(datetime, reference_datetime, pubDate, model_id, site_id, depth, variable)) |>
  dplyr::mutate(family = "bernoulli",
                parameter = "prob",
                variable = "IceCover_binary_max",
                depth = NA) |>
  dplyr::rename(depth_m = depth) |>
  dplyr::select(reference_datetime, datetime, model_id, site_id, depth_m, family, parameter, variable, prediction)

# Calculate probablity of being mixed
min_depth <- 1
max_depth <- 8
threshold <- 0.1

temp_forecast <- forecast_df |>
  filter(depth %in% c(min_depth, max_depth),
         variable == "Temp_C_mean") |>
  pivot_wider(names_from = depth, names_prefix = 'wtr_', values_from = prediction)

colnames(temp_forecast)[which(colnames(temp_forecast) == paste0('wtr_', min_depth))] <- 'min_depth'
colnames(temp_forecast)[which(colnames(temp_forecast) == paste0('wtr_', max_depth))] <- 'max_depth'

mix_binary <- temp_forecast |>
  mutate(min_depth = rLakeAnalyzer::water.density(min_depth),
         max_depth = rLakeAnalyzer::water.density(max_depth),
         mixed = ifelse((max_depth - min_depth) < threshold, 1, 0)) |>
  summarise(prediction = 100*(sum(mixed)/n()), .by = c(datetime, reference_datetime, pubDate, model_id, site_id, variable)) |>
  dplyr::mutate(family = "bernoulli",
                parameter = "prob",
                variable = "Mixed_binary_sample",
                depth = NA) |>
  dplyr::rename(depth_m = depth) |>
  dplyr::select(reference_datetime, datetime, model_id, site_id, depth_m, family, parameter, variable, prediction)


# Combine into a vera data frame
vera4cast_df <- forecast_df |>
  dplyr::rename(depth_m = depth) |>
  dplyr::mutate(prediction = ifelse(variable == "DO_mgL_mean", prediction/1000*(32),prediction),
                prediction = ifelse(variable == "fDOM_QSU_mean", 151.3407 + prediction/29.62654,prediction),
                prediction = ifelse(variable == "NIT_amm", prediction/1000/0.001/(1/18.04),prediction),
                variable = ifelse(variable == "NIT_amm", "NH4_ugL_sample", variable),
                prediction = ifelse(variable == "NIT_nit", prediction/1000/0.001/(1/62.00),prediction),
                variable = ifelse(variable == "NIT_amm", "NO3NO2_ugL_sample", variable),
                prediction = ifelse(variable == "PHS_frp", prediction/1000/0.001/(1/94.9714),prediction),
                variable = ifelse(variable == "PHS_frp", "SRP_ugL_sample", variable),
                prediction = ifelse(variable == "CAR_dic", prediction/1000/(1/52.515), prediction),
                variable = ifelse(variable == "CAR_dic", "DIC_mgL_sample", variable),
                variable = ifelse(variable == "CAR_ch4", "CH4_umolL_sample", variable),
                variable = ifelse(variable == "secchi", "Secchi_m_sample", variable),
                depth_m = ifelse(depth_m == 0.0, 0.1, depth_m)) |>
  dplyr::select(-pubDate,-forecast, -variable_type) |>
  dplyr::mutate(parameter = as.character(parameter)) |>
  dplyr::bind_rows(bloom_binary) |>
  dplyr::bind_rows(ice_binary) |>
  dplyr::bind_rows(mix_binary) |>
  dplyr::filter(variable %in% vera_variables) |>
  mutate(project_id = "vera4cast",
         model_id = config$run_config$sim_name,
         family = "ensemble",
         site_id = "fcre",
         duration = "P1D",
         datetime = lubridate::as_datetime(datetime),
         reference_datetime = lubridate::as_datetime(reference_datetime)) |>
  filter(datetime >= reference_datetime)

#vera4cast_df |>
#  filter(depth_m == 1.6 | is.na(depth_m)) |>
#  ggplot(aes(x = datetime, y = prediction, group = factor(parameter))) +
#  geom_line() +
#  facet_wrap(~variable, scale = "free")

file_name <- paste0(config$run_config$sim_name,
                    "-",
                    lubridate::as_date(vera4cast_df$reference_datetime[1]),".csv.gz")

readr::write_csv(vera4cast_df, file = file_name)



#FLAREr::generate_forecast_score_arrow(targets_file = file.path(config$file_path$qaqc_data_directory,paste0(config$location$site_id, "-targets-insitu.csv")),
#                                      forecast_df = forecast_df,
#                                      use_s3 = config$run_config$use_s3,
#                                      bucket = config$s3$scores$bucket,
#                                      endpoint = config$s3$scores$endpoint,
#                                      local_directory = file.path(lake_directory, "scores/parquet"))

#message("Generating plot")
#FLAREr::plotting_general_2(file_name = saved_file,
#                           target_file = file.path(config$file_path$qaqc_data_directory, paste0(config$location$site_id, "-targets-insitu.csv")),
#                           ncore = 2,
#                           obs_csv = FALSE)

FLAREr::put_forecast(saved_file, eml_file_name = NULL, config)

forecast_start_datetime <- lubridate::as_datetime(config$run_config$forecast_start_datetime) + lubridate::days(1)
start_datetime <- lubridate::as_datetime(config$run_config$forecast_start_datetime)
restart_file <- paste0(config$location$site_id,"-", (lubridate::as_date(forecast_start_datetime)- days(1)), "-",config$run_config$sim_name ,".nc")

FLAREr::update_run_config2(lake_directory = lake_directory,
                           configure_run_file = configure_run_file,
                           restart_file = restart_file,
                           start_datetime = start_datetime,
                           end_datetime = NA,
                           forecast_start_datetime = forecast_start_datetime,
                           forecast_horizon = config$run_config$forecast_horizon,
                           sim_name = config$run_config$sim_name,
                           site_id = config$location$site_id,
                           configure_flare = config$run_config$configure_flare,
                           configure_obs = config$run_config$configure_obs,
                           use_s3 = config$run_config$use_s3,
                           bucket = config$s3$warm_start$bucket,
                           endpoint = config$s3$warm_start$endpoint,
                           use_https = TRUE)

Sys.unsetenv("AWS_ACCESS_KEY_ID")
Sys.unsetenv("AWS_SECRET_ACCESS_KEY")
vera4castHelpers::submit(file_name, first_submission = FALSE)


